#### exit脚本
```
#!/bin/bash
for i in `seq 1 5`
do
        echo $i
        if [ $i -eq 3 ]
        then
            exit 1
        fi
        echo $i
done
echo aaaaa

```
#### break脚本
```
#!/bin/bash
for i in `seq 1 5`
do
        echo $i
        if [ $i -eq 3 ]
        then
            break
        fi
        echo $i
done
echo aaaaa

```
#### continue脚本
```
#!/bin/bash
for i in `seq 1 5`
do
        echo $i
        if [ $i -eq 3 ]
        then
            continue
        fi
        echo $i
done
echo aaaaa    
```

#### 本案例参考脚本
```
#!/bin/bash
#日志切割归档，按天切割，1.log变1.log.1, 1.log.1变1.log.2, ...
#作者：阿铭
#日期：2018-11-1

logdir=/data/logs/

#定义函数，如果一个文件存在，则删除
function e_df()
{
    if [ -f $1 ]
    then
        rm -f $1
    fi
}

cd $logdir

#从7到2，依次遍历循环
for i in `seq 7 -1 2`
do
    #$i2比$i小1
    i2=$[$i-1]
    
    #首先判断1.log.7是否存在，若存在则删除
    e_df  1.log.$i

    #当1.log.6存在，则把1.log.6改名为1.log.7，依次类推
    if [ -f  1.log.$i2 ]
    then
        mv  1.log.$i2 1.log.$i
    fi
done

#由于1.log后面无后缀，所以不能走上面的for循环，只能另外拿出来处理
e_df 1.log.1
mv  1.log 1.log.1

##说明：这个脚本写完后，放到计划任务里，每天0点0分执行。
```
#### 扩展脚本
```
#!/bin/bash
#日志切割归档，按日志大小切割（100M），1.log变1.log.1, 1.log.1变1.log.2, ...
#作者：阿铭
#日期：2018-11-1

logdir=/data/logs/

#技术1.log大小
size=`du -sk $logdir/1.log |awk '{print $1}`

#如果1.log小于100M，则退出脚本
if [ $size -lt 10240 ]
then
    exit 0
fi

#定义函数，如果一个文件存在，则删除
function e_df()
{
    if [ -f $1 ]
    then
        rm -f $1
    fi
}

cd $logdir

#如果1.log.1存在，则先把它压缩为1.log.1.gz，这样下面的for循环才不会出错
if [ -f 1.log.1 ]
then
    gzip 1.log.1
fi
#由于1.log.1已经被压缩为1.log.gz，所以可以直接将1.log改名为1.log.1
mv  1.log 1.log.1

#从7到2，倒序循环
for i in `seq 7 -1 2`
do
    #$i2比$i小1
    i2=$[$i-1]
    
    #首先判断1.log.7.gz是否存在，若存在则删除
    e_df  1.log.$i.gz

    #当1.log.6.gz存在，则把1.log.6.gz改名为1.log.7.gz，依次类推
    if [ -f  1.log.$i2.gz ]
    then
        mv  1.log.$i2.gz 1.log.$i.gz
    fi
done

##说明：由于我们需要按照日志大小切割，所以这个脚本写完后，需要每分钟执行一次。
```
